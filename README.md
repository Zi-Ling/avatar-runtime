English | [中文](README_ZH.md)

# avatar-runtime

A minimal **execution runtime** for LLM-generated plans.

This project focuses on **deterministic execution**,
**fail-fast validation**, and **policy-gated actions** —
not planning, memory, or intelligence.

If a plan is incomplete, unsafe, or ambiguous,
this runtime refuses to guess, auto-fix, or silently retry.

---

## Why this exists

In real-world agent systems, most failures do **not** come from the LLM itself.

They usually come from the execution layer:

- Missing or malformed parameters
- Unsafe or over-privileged actions
- Silent retries that hide real errors
- Non-replayable, non-auditable runs

**avatar-runtime** isolates and addresses these problems by enforcing
**strict execution semantics** between a generated plan and the real world.

---

## What this project is

- A deterministic execution runtime
- A fail-fast validator for structured plans
- A policy gate for unsafe actions
- A traceable, replayable execution loop

## What this project is NOT

- An agent framework
- A planner or task decomposer
- A memory or context system
- An automation toolkit
- An LLM wrapper

This project intentionally avoids intelligence and focuses purely on
**execution correctness**.

This runtime is designed to be **embedded**, not used directly by end users.

---

## Where this fits

This repository intentionally demonstrates only a **single slice**
of a larger agent system.

The execution runtime shown here normally sits **after** planning,
and **before** any real-world side effects.

In a full system, this layer would be called with:

- A structured plan generated by an LLM
- Explicit parameters resolved from context
- Strict execution policies defined by the host application

This demo omits those upstream components on purpose,
to keep execution behavior observable, testable, and deterministic.

For context on why this runtime exists, see [this write-up](docs/why_execution_breaks.md).

---

## Quick start

Clone the repository and run the demo:

    python run_demo.py

The demo runs three execution cases:

1. **Successful execution**  
   A simple file workflow that completes end-to-end.

2. **Schema validation failure**  
   A step with missing required parameters fails immediately, before execution.

3. **Policy denial**  
   An unsafe file operation is blocked by execution policy.

Each run produces **replayable trace artifacts** under:

    ./workspace/artifacts/

---

## Demo behavior

- Step-by-step execution order
- Validation failures before any side effects
- Policy denials with clear reasons
- Deterministic trace files for every run

Example artifacts:

    trace_success.json
    trace_missing_param.json
    trace_policy_block.json

These traces are intended to be inspected, replayed, or analyzed —
not just logged.

---

## Design principles

- **Fail fast** — invalid inputs are rejected immediately
- **No silent recovery** — no guessing or implicit retries
- **Policy before execution** — unsafe actions never run
- **Deterministic traces** — every run is auditable

---

## Project structure

    runtime/        execution engine, validation, policy, tracing
    skills/         minimal builtin skills (file only)
    examples/       demo plans and runner
    run_demo.py     top-level demo entrypoint
    workspace/      sandboxed execution output (gitignored)

The project is intentionally small and explicit.

---

## Status

This repository is an **experimental extraction** from a larger agent system,
intended to demonstrate execution-layer behavior in isolation.

The API is not stable and the scope is intentionally limited.

---

## License

MIT
